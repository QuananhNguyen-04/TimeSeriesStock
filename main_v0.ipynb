{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# import torch_directml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the TimeSeriesDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        seq = self.data[i : i + self.seq_len]\n",
    "        label = self.data[i + self.seq_len, -2]\n",
    "        return {\n",
    "            \"seq\": seq.clone().detach().float(),\n",
    "            \"label\": label.clone().detach().float().unsqueeze(0),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=10):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 2 * hidden_dim)\n",
    "        self.fc2 = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        self.h0 = None\n",
    "        self.c0 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        if (\n",
    "            self.h0 is None\n",
    "            or self.c0 is None\n",
    "            or self.h0.shape[1] != x.shape[0]\n",
    "            or self.c0.shape[1] != x.shape[0]\n",
    "        ):\n",
    "            \n",
    "            self.h0 = torch.zeros(\n",
    "                self.rnn.num_layers, x.size(0), self.rnn.hidden_size\n",
    "            ).to(x.device)\n",
    "            self.c0 = torch.zeros(\n",
    "                self.rnn.num_layers, x.size(0), self.rnn.hidden_size\n",
    "            ).to(x.device)\n",
    "\n",
    "        out, (self.h0, self.c0) = self.rnn(x, (self.h0, self.c0))\n",
    "\n",
    "        # Detach hidden states from the computation graph to prevent backpropagation\n",
    "        self.h0 = self.h0.detach()\n",
    "        self.c0 = self.c0.detach()\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = torch.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the device, model, criterion, and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.device = torch_directml.device()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model(input_dim=6, hidden_dim=64, output_dim=1, num_layers=10).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BID.csv\n",
      "Processing BVH.csv\n",
      "Processing CTG.csv\n",
      "Processing FPT.csv\n",
      "Processing GAS.csv\n",
      "Processing HDB.csv\n",
      "Processing HPG.csv\n",
      "Processing KDH.csv\n",
      "Processing MBB.csv\n",
      "Processing MSN.csv\n",
      "Processing MWG.csv\n",
      "Processing NVL.csv\n",
      "Processing PDR.csv\n",
      "Processing PLX.csv\n",
      "Processing PNJ.csv\n",
      "Processing POW.csv\n",
      "Processing REE.csv\n",
      "Processing SBT.csv\n",
      "Processing SSI.csv\n",
      "Processing STB.csv\n",
      "Processing TCB.csv\n",
      "Processing TCH.csv\n",
      "Processing TPB.csv\n",
      "Processing VCB.csv\n",
      "Processing VHM.csv\n",
      "Processing VIC.csv\n",
      "Processing VJC.csv\n",
      "Processing VNM.csv\n",
      "Processing VPB.csv\n",
      "Processing VRE.csv\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for csv_file in os.listdir(\"./data\"):\n",
    "    if not csv_file.endswith(\".csv\"):\n",
    "        continue\n",
    "    print(f\"Processing {csv_file}\")\n",
    "    file = open(f\"./data/{csv_file}\", \"r\")\n",
    "\n",
    "    stock_name = csv_file.split(\".\")[0]\n",
    "    df = pd.read_csv(\n",
    "        file,\n",
    "        header=1,\n",
    "        names=[\"ticker\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"],\n",
    "    )\n",
    "    df = df.sort_values(by=\"date\", ascending=True)\n",
    "    data[stock_name] = torch.tensor(df.iloc[:, 1:].values)\n",
    "\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Create the dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836\n",
      "11398\n",
      "9119 2279\n"
     ]
    }
   ],
   "source": [
    "dataset = TimeSeriesDataset(data[\"BID\"], seq_len=10)\n",
    "print(len(dataset))\n",
    "merged_dataset = dataset\n",
    "for i, stock_name in enumerate(data):\n",
    "    if stock_name == \"BID\":\n",
    "        continue\n",
    "    merged_dataset = ConcatDataset(\n",
    "        [merged_dataset, TimeSeriesDataset(data[stock_name], seq_len=10)]\n",
    "    )\n",
    "    if i % 3 == 0:\n",
    "        break\n",
    "print(len(merged_dataset))\n",
    "train_dataset, test_dataset = random_split(merged_dataset, [0.8, 0.2])\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq': tensor([[20140124.0000,    14.4241,    14.8037,    14.0446,    14.2723, 8417060.0000],\n",
      "        [20140128.0000,    14.1964,    14.2723,    13.7409,    13.9686, 3240910.0000],\n",
      "        [20140206.0000,    13.8168,    13.8927,    13.3613,    13.3613, 959590.0000],\n",
      "        [20140208.0000,    13.2095,    13.2854,    12.5262,    12.6021, 2987600.0000],\n",
      "        [20140210.0000,    12.5262,    13.0576,    12.2984,    12.9058, 4052090.0000],\n",
      "        [20140212.0000,    13.0576,    13.0576,    12.8299,    12.8299, 1938480.0000],\n",
      "        [20140212.0000,    12.7540,    12.8299,    12.6781,    12.7540, 1176180.0000],\n",
      "        [20140212.0000,    12.7540,    12.8299,    12.6022,    12.6021, 2156140.0000],\n",
      "        [20140214.0000,    12.7539,    12.9058,    12.6021,    12.7540, 1489380.0000],\n",
      "        [20140216.0000,    12.8299,    12.8299,    12.6022,    12.6781, 1173560.0000],\n",
      "        [20140218.0000,    12.6781,    12.6781,    12.6022,    12.6021, 1861540.0000],\n",
      "        [20140220.0000,    12.6780,    12.7539,    12.5262,    12.6021, 2988120.0000],\n",
      "        [20140220.0000,    12.6780,    13.0576,    12.6021,    12.8299, 3243650.0000],\n",
      "        [20140220.0000,    12.7540,    12.7540,    12.6781,    12.6781, 903040.0000],\n",
      "        [20140224.0000,    12.7540,    12.7540,    12.6022,    12.6781, 833430.0000],\n",
      "        [20140224.0000,    12.6022,    12.6781,    12.5263,    12.6781, 1249150.0000],\n",
      "        [20140226.0000,    12.6781,    12.8299,    12.6022,    12.6781, 1399670.0000],\n",
      "        [20140228.0000,    12.6781,    13.2095,    12.6781,    12.8299, 3731900.0000],\n",
      "        [20140228.0000,    12.7540,    12.9058,    12.7540,    12.9058, 1154560.0000],\n",
      "        [20140304.0000,    12.8299,    12.9058,    12.6781,    12.6781, 954830.0000]]), 'label': tensor([12.6021])}\n"
     ]
    }
   ],
   "source": [
    "print(merged_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|                                              | 0/285 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|███████████████████████| 285/285 [00:19<00:00, 14.84step/s, loss=19.598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:   1 train: 19.283| test: 19.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|███████████████████████| 285/285 [00:18<00:00, 15.54step/s, loss=22.203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:   2 train: 19.276| test: 19.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100:  23%|█████▌                  | 66/285 [00:04<00:15, 14.42step/s, loss=22.002]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(criterion(out, label))\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 36\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh0\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc0\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m---> 36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    with tqdm(dataloader, unit=\"step\", ncols=90, desc=f\"Epoch {epoch + 1}/{epochs}\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(seq)\n",
    "            loss = torch.sqrt(criterion(out, label))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=f\"{loss.item():.3f}\")\n",
    "    running_loss /= len(dataloader)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        testing_loss = 0.0\n",
    "        for i, batch in enumerate(testloader):\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            out = model(seq)\n",
    "            loss = torch.sqrt(criterion(out, label))\n",
    "            testing_loss += loss.item()\n",
    "        if (epoch+1) % 3 == 0:\n",
    "            for pred, act in zip(out[:10], label[:10]):\n",
    "                print(f\"Pred: {pred.item()}, Actual: {act.item()}\")\n",
    "            \n",
    "        print(\n",
    "            f\"Epochs: {epoch+1:3d} train: {running_loss :.3f}| test: {testing_loss / (len(testloader)):.3f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
